{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pytorch (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tensors\n",
    "# a tensor is a number, vector, matrix, or any n-dimensional array\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(4., requires_grad=True)\n",
      "tensor(5., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print and see the tensors\n",
    "print(x)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# let's combine these tensors\n",
    "y = w * x + b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use torch to computer the derivative of y w.r.t. the tensors that have requires_grad set to True\n",
    "y.backward() # compute the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# display the gradients\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "- A model that predicts crop yields or apples and oranges\n",
    "- We want to find a set of weights and biases using a set of training data and make predictions from then\n",
    "\n",
    "```\n",
    "yield_apple = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "\n",
    "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data\n",
    "- The data are 2 matrices - the input and the traget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input (temp, rainfall, humidity)\n",
    "inputs = np.array([\n",
    "    [73, 67, 43],\n",
    "    [91, 88, 64],\n",
    "    [87, 134, 58],\n",
    "    [102, 43, 37],\n",
    "    [69, 96, 70]], dtype = 'float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets (apples, oranges)\n",
    "targets = np.array([\n",
    "    [56, 70],\n",
    "    [81, 101],\n",
    "    [119, 133],\n",
    "    [22, 37],\n",
    "    [103, 119]], dtype = 'float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# now our inputs and targets are ready, we can convert them to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "- We pick some random values to be the weights and biases of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9699, -0.8580, -1.2345],\n",
      "        [-0.3736,  0.1180, -0.6072]], requires_grad=True)\n",
      "tensor([-1.3427,  1.2633], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -41.1086,  -44.2140],\n",
      "        [ -67.5922,  -61.2124],\n",
      "        [-103.5314,  -50.6479],\n",
      "        [  15.0156,  -54.2363],\n",
      "        [-103.1998,  -55.6929]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# print the targets (actual)\n",
    "print(targets)  \n",
    "\n",
    "# notice that the predictions are way off the actual targets\n",
    "# since we use random weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Loss Function\n",
    "- We will use the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23552.3047, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above value is the loss that shows how bad the model is at predicting the target variables. Generally, the lower the loss, the better.\n",
    "\n",
    "- We can also compute the loss gradients w.r.t the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9699, -0.8580, -1.2345],\n",
      "        [-0.3736,  0.1180, -0.6072]], requires_grad=True)\n",
      "tensor([[-10982.2500, -13899.4238,  -8256.9609],\n",
      "        [-12087.2471, -13445.9062,  -8309.7246]])\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3427,  1.2633], requires_grad=True)\n",
      "tensor([-136.2833, -145.2007])\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Calculus Knowledge\n",
    "- Gradient is the rate of change of the loss\n",
    "- Positive gradient means increasing/decreasing the element's value will increase/decrease the loss\n",
    "- In work the other way round for negative gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# reset the gradient to zero\n",
    "# torch will accumulate the gradients\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting `w` and `b` using Gradient Descent\n",
    "Workflows as follow\n",
    "- Generate predictions\n",
    "- Calculate the loss\n",
    "- Compute gradients w.r.t `w` and `b`\n",
    "- Adjust the weights\n",
    "- Reset to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -41.1086,  -44.2140],\n",
      "        [ -67.5922,  -61.2124],\n",
      "        [-103.5314,  -50.6479],\n",
      "        [  15.0156,  -54.2363],\n",
      "        [-103.1998,  -55.6929]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# generate the predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23552.3047, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# compute the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust weights and reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0797, -0.7190, -1.1519],\n",
      "        [-0.2527,  0.2524, -0.5241]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16467.3594, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# recalculate the loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that with the new weights and biases, we can reduce the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Multiple Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(610.6926, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# calculate the loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 67.4894,  73.4702],\n",
      "        [ 80.7470,  95.2535],\n",
      "        [105.4114, 140.1996],\n",
      "        [ 81.5402,  53.3925],\n",
      "        [ 63.8350, 100.4080]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# see the predictions\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# see the actual targets (quite good than random)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Linear Regression Using Torch's Builtins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "inputs = np.array([\n",
    "    [73, 67, 43],\n",
    "    [91, 88, 64],\n",
    "    [87, 134, 58],\n",
    "    [102, 43, 37],\n",
    "    [69, 96, 70],\n",
    "    [74, 66, 43],\n",
    "    [91, 87, 65],\n",
    "    [88, 134, 59],\n",
    "    [101, 44, 37],\n",
    "], dtype = 'float32')\n",
    "\n",
    "targets = np.array([\n",
    "    [56, 70],\n",
    "    [81, 101],\n",
    "    [119, 133],\n",
    "    [22, 37],\n",
    "    [103, 119],\n",
    "    [57, 69],\n",
    "    [80, 102],\n",
    "    [118, 132],\n",
    "    [21, 38],\n",
    "], dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 73.,  67.,  43.],\n",
       "         [ 87., 134.,  58.],\n",
       "         [ 74.,  66.,  43.],\n",
       "         [101.,  44.,  37.],\n",
       "         [ 69.,  96.,  70.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [119., 133.],\n",
       "         [ 57.,  69.],\n",
       "         [ 21.,  38.],\n",
       "         [103., 119.]])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the data loader\n",
    "batch_size = 5  \n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size, shuffle=True)\n",
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1982,  0.1240, -0.1796],\n",
      "        [-0.0325, -0.3151,  0.1114]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5711, -0.4596], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "opt =  torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11864.3721, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# import nn.functional\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the loss function\n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "# see the loss\n",
    "loss = loss_fn(model(inputs), targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            # generate predictions\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "            # update parameters using gradients\n",
    "            opt.step()\n",
    "            # reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "    print('Training loss: ', loss_fn(model(inputs), targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  tensor(15.7548, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 57.0276,  70.6110],\n",
      "        [ 78.4118,  98.3808],\n",
      "        [122.0059, 134.1201],\n",
      "        [ 24.8582,  41.7886],\n",
      "        [ 93.4030, 112.5369],\n",
      "        [ 55.8097,  69.6003],\n",
      "        [ 77.7269,  98.1593],\n",
      "        [122.0261, 134.5751],\n",
      "        [ 26.0760,  42.7993]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.],\n",
      "        [ 57.,  69.],\n",
      "        [ 80., 102.],\n",
      "        [118., 132.],\n",
      "        [ 21.,  38.]])\n"
     ]
    }
   ],
   "source": [
    "# compare with real targets\n",
    "print(targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
